\section{PingLoad: Application Fingerprint} \label{PingLoad}
\subsection{PRI Outliers}
%Observation of PRI outliers
In \Cref{Sec:DistinguishDevice}  we mentioned the phenomenon that processor occupied by other tasks may prolong the PRI as illustrated in  \Cref{PingloadExample}. Extracting these outliers on a CC2538 running Helloworld example using threshold of $\geq 11$ms, we show the distribution of these prolonged PRIs in \Cref{PingLoadOutliers}. The histogram suggests the distribution has a strong discrete tendency, with multiple spikes presented in the graph.

\AddFigure{fig/helloworld_cc2538_outlier.png}{Histogram of PRI Outliers on CC2538 running Helloworld Example, using bins of $10$ms}{PingLoadOutliers}

We suppose the cause of such discreteness is that the delay is indeed caused by context switching in the kernel; therefore the impact of remaining time for the current task is indeed negligible. We further suppose the existence of multiple spikes is the result of switching from different contexts take different amounts of time. However, due to practical reasons, we found it difficult to experimentally confirm these hypothesises. Nevertheless, we consider this result as a strong indication that different states of the processor would result into different value of PRI, as illustrated in \Cref{PingLoadTheory}.

\begin{figure}[ht!]
	\center
	\begin{subfigure}{0.8\textwidth}
	{
		\center
		\includegraphics[width=\textwidth]{fig/PingLoad_temperature.png}
	}
	\subcaption{PRI when reading temperature sensor}
	\end{subfigure}
	\begin{subfigure}{0.8\textwidth}
	{
		\center
		\includegraphics[width=\textwidth]{fig/PingLoad_als.png}
		\subcaption{PRI when reading Ambient Light Sensor(ALS)}
	}
	\end{subfigure}
	\caption{An example of reading temperature and ALS sensor results into different PRI.}
	\label{PingLoadTheory}
\end{figure}

\subsection{PingLoad Attack}
%What is PingLoad
The PingLoad attack is proposed to exploit the distribution of PRI outliers as an indicator of different states of the processor. Considering the fact that many IoT applications perform routine operations, e.g. reading temperature sensor periodically, the constitution of processor states can be effectively viewed as a fingerprint to the application running on the node. 

To verify the effectiveness of this attack, we performed a proof of concept experiment.

%Manual
%Therefore when sending a large amount of PING packets to different node running different applications, those prolonged PRIs would show distinctive distributions for different nodes performing different operations. \Cref{PingLoadTheory} illustrates an example that reading temperature sensor and ALS prolongs PRIs differently. 

%The PingLoad attack hence uses such prolonged PRI distributions as fingerprints to different applications, matching an unknown application to known applications by finding  the statistically most similar PRI distribution. To be more specifically, the attack is described using a ``closed world'' setting with the following steps:

\subsubsection{Experiment Design}

Similar to many Traffic Analysis literature, we adopted the ``closed world'' setting for the experiment. Formally, our experiment simulates the following scenario:
\begin{itemize}
 \item The adversary is given the pre-knowledge of $n$ potential candidate applications, denote as $\mathbb{A} = \{A_1, A_2, ..., A_n\}$, and a target node running an unknown application $A_{x^*}$ where $A_{x^*} \in \mathbb{A}$. The adversary is also given the exact same hardware of target as well as the power to send PING packets to the target.
 \item The adversary eventually outputs $x$ as the guess of $x^*$. The attack is considered effective if $P(x = x^*) > \frac{1}{n}$.
\end{itemize}

In reality, such scenario can be motivated as an adversary trying to find out which product a victim might be using among those available on the market.

\subsubsection{Attack Description}

The attack can be described into 4 stages:

\begin{description}
	\item[Profiling]
	To set up the attack, the adversary collects PRIs for each application in $\mathbb{A}$. We denote the profiled traces as:
	\begin{equation}
		\mathbb{T}_p = \{T_1, T_2, ..., T_n\}
	\end{equation}
where each $T_i$ is collected by repetitively sending PING Request to the device running application $A_i$. Each trace $T_i$ contains multiple PRIs, denote as:
	\begin{equation}
		T_i = \{t_{(i,1)}, t_{(i,2)}, ..., t_{(i,{m_i})}\} %\text{ for } i \in [1,n]
	\end{equation}
	where $m_i$ is the number of PRIs in $T_i$.

	\item[Collecting Target Trace]
	To identify the secret application $A_{x^*}$, the adversary collects the PRIs on the target node running $A_{x^*}$. We denote the target trace as:
	\begin{equation}
		T_{x^*} = \{ t_{(x^*,1)}, t_{(x^*,2)}, ..., t_{(x^*,{m_x})}\} % PRI_^x_1, $%PRI^x_2, ..., PRI^x_{m_x}\}$.
	\end{equation}
	
	\item[Matching Fingerprint]
	The first step of matching fingerprint is to filter out the outliers in each trace by a threshold $\alpha$. In practice, such threshold can be easily determined from a trace. For example, for the data we have shown in \Cref{PRIs}, $11$ms is a reasonable choice of $\alpha$ for CC2538, as most PRIs are within the range of $[9,10.5]$(ms).
	
	We then filter each trace in $\mathbb{T}$ by keeping only PRIs $\geq \alpha$:
	\begin{equation}
		T^{\prime}_{i} = \{t \in T_i | t \geq \alpha\}
	\end{equation}
	
	We denote the set of filtered profiling traces as:
	\begin{equation}
		\mathbb{T}^{\prime}_{p} = \{ T^{\prime}_1, T^{\prime}_2, ..., T^{\prime}_n\}
	\end{equation}
	Indeed the filtering of profiled traces could also be pre-computed.
	
	We then apply the same filter on target trace:
	\begin{equation}
		T^{\prime}_{x^*} =  \{t \in T_{x^*} | t > \alpha\}
	\end{equation}
	
	The adversary then searches for $T^{\prime}_{x} \in \mathbb{T}^{\prime}_p$ that is statistically most similar to $T^{\prime}_{x^*}$. One way is to use Kolmogorov-Smirniov Distance (KS distance) as the measurement of statistical similarity. The adversary then  outputs the index of the trace with minimum KS-distance to the target, i.e. to search $T^{\prime}_x$ such that:
	\begin{equation}
		KSD( T^{\prime}_{x}, T^{\prime}_{x^*}) = min(\{KSD(T^{\prime}_i, T^{\prime}_{x^*}) | i \in [1,n]\})
	\end{equation}
	where $KSD(X, Y)$ represents the KS distance between two distributions $X$ and $Y$.	Finally the adversary outputs $x$ as the guess of $x^*$.
\end{description}

\subsubsection{Experiment Result}

We used 10 applications to test the PingLoad attack:
\begin{itemize}
	\item The \textbf{powertrace} example in Contiki source code which records the power consumption of the node.
	\item The \textbf{broadcast} example in Contiki source code which broadcasts the string ``Test'' periodically.
	\item The \textbf{sensorpayload} application family we developed. These applications periodically encrypt some sensor readings and send them back to the network root. We developped $8$ sensorpayload applications corresponding to $8$ different combinations of temperature, light and voltage sensors.
\end{itemize}

We  ran all applications on a CC2538 device. The PING requests are sent from a Linux host using ``ping6 -s 0 -i 0.4'', i.e. no user defined data and with interval of $0.4$ second. The frequency of PING is configured to such value to maximise the speed of collection without flooding the node.

For each application, we collected $2$ groups of packets dumps (pcapng files), with each dump consists of $200000$ packets. Traces of nearly $7000$ PRIs are extracted from each dump. Applying the empirical $11$ms threshold for CC2538, we gathered roughly 1000 PRIs from each filtered trace those are prolonged by the application. \Cref{PingLoadApps} summarises the data we used in the experiment.

For each of the 20 traces, we computed the KS-distances against all other 19 traces, with only one collected on the same application. \Cref{ksdistances} shows the result of KS-distances. Referring the indexes of minimum KS-distances in each row in \Cref{ksdistances} to \Cref{PingLoadApps}, our experiment reported 13 out of 20 ($65$\%) cases have successfully matched to the correct applications in our setting.

\paragraph{Analysis of Effectiveness}

Assume the traces does not contain any information of their corresponding application, i.e. each trace is uniformly randomly matched to one in the other 19 traces. The theoretical probability $P_0$ of having 13 out of 20 traces correctly matched is:
\begin{equation*}
P_0 = C^{13}_{20} (\frac{1}{19})^{13} (\frac{18}{19})^{7} \approx 1.262 * 10^{-12} \leq 0.01
\end{equation*}

Therefore we reject the hypothesis and conclude that the traces contain information of the applications.