\chapter{Literature Review}

\section{Academic Publications}

\cite{Web1} demonstrated that this kind of  leakage indeed exists in some web applications. Firstly, different web page has different page sizes; thus the size can be exploited as a fingerprint to indicate which page the victim accessed. Secondly, on some pages where part of its content is generated dynamically, such as suggestions in a search box, the size of the dynamic content can again be used as a fingerprint and therefore reveal the victim's input which is supposed to be kept secret.

\cite{Web2} focuses on detecting leakage points of input in web applications. In this paper, a web applications is modelled as a finite state machine. Observable packet information, such as length and flags in a TCP header, are represented as a vector. A trace is then defined as a sequence of packet information. The leakage points are then measured by estimating the mutual information of  the input and each point in the trace. As an extension to mutual information analysis, \cite{DBLP:conf/csfw/AlvimCPS12} and \cite{DBLP:conf/csfw/ChothiaG11} provide methods to improve accuracy and performance of the test.

\cite{Web1} and \cite{Web2} together lay a foundation to this project. \cite{Web1} focuses more on the fact that information leakage through encrypted network traffic actually exists but the attacks it describes are relatively web-site specific, although this could be a feature in this subject. The mutual information test proposed in \cite{Web2} is a powerful tool to pinpoint the leakage points but it also suffers from a performance issue as it requires a huge amount of computation.

\cite{Danezis_trafficanalysis} and \cite{DBLP:journals/iacr/SchaubSHCJTHGR14} described two actual attacks using packet length. \cite{Danezis_trafficanalysis} uses packet length to fingerprint pages which contains potentially privacy information. \cite{DBLP:journals/iacr/SchaubSHCJTHGR14} attacks search keyword by profiling the size of response for each character typed in the search box, then matches the victim's traffic in a suffix tree built for the dictionary by a stochastic algorithm.

Packet length might be the most juicy target in packet analysis attacks. These are particularly efficient and requires only passive observation and not much effective countermeasures are proposed. However, the effectiveness of these attacks might be affected by divergence of packet lengths which can be seen common as a result of ads or other kinds of dynamic contents in web pages. One potential problem in \cite{DBLP:journals/iacr/SchaubSHCJTHGR14} is that the profiling step takes a long time due to the response time of search engine and the dictionary chosen also has a great impact on the efficiency and accuracy of attack. It might be worthy pointing out that most theoretical cryptographical research studies only secrecy of plaintexts with same length which is not the case in real world. I personally think that these attacks exploited a blind spot in theoretic study and have displayed the gap between theoretical world and practical world. Packet length is also the most studied side channel information in our experiment at this stage. (See \Cref{Chp: Progress To Date})

Compression ratio obtained by toggling the compress flag in some protocol can also be exploited to recover plaintext. The general idea of this kind of attack is described in \cite{DBLP:conf/fse/Kelsey02}. This attack requires the adversary being able to inject his guesses of plaintext into the uncompressed plaintext. The compression ratio will be relatively higher when the guess matches part of the plaintext and lower if it does not. \cite{CRIME} and \cite{BREACH} gave implementations against TLS and HTTPS in real scenarios respectively. \cite{DBLP:journals/iacr/AlawatugodaSB14a} proposed some countermeasures by disabling compression or inducing some length hiding mechanism.

At a first glance, the partial plaintext control assumption in \cite{DBLP:conf/fse/Kelsey02} seems to be weird, but \cite{BREACH} has demonstrated that such circumstances can be practically achieved by a phishing link. Further more, some crucial information can be attacked such as the session cookie which can then be used to hijack a https session, like on-line banking. As an impact of these attacks, the latest TLS standard has disabled the usage of compression. Nevertheless, when it comes to constrained environment where bandwidth becomes precious, a solution better than totally forbidden is desired. However, there is no compression in our current set up(see \Cref{Chp: Progress To Date}). This kind of attack is not considered at this stage.

\cite{DBLP:conf/eurocrypt/Vaudenay02} exploits the padding scheme of CBC mode\footnote{\url{http://en.wikipedia.org/wiki/Block_cipher_mode_of_operation\#Cipher_Block_Chaining_.28CBC.29}}
 to recover the plaintext. This attack is based on the fact that some SSL implementation returns different error messages on padding error and MAC failure. Since the padding verification is done after decryption but before MAC verification, the adversary can send to the server a partially modified ciphertext and recover the plaintext by different error messages. Although one countermeasure against this attack is to unify the error messages, \cite{DBLP:conf/sp/AlFardanP13} states that it is still possible to distinguish these errors by measuring the time difference induced by whether a MAC verification is performed.

The countermeasure against the attack in \cite{DBLP:conf/eurocrypt/Vaudenay02} has been adopted in many recent implementations by unifying the error message. The attack described \cite{DBLP:conf/sp/AlFardanP13} relies on the heartbeat being turned on and is very sensitive to network latency. Above that as stated in the paper that adding a idle time before respond can effectively prevent this attack. For a sensor network, the time resolution is expected to be higher due to the low processing power of devices. It is not clear at this stage whether this will raise the risk of this attack. However, the cipher suite adopted by our current experimental environment does not have any padding at all(see \Cref{Chp: Progress To Date}); hence this kind of attack is not being considered at this stage.

\section{Standard Specifications}
Another part of the related literatures are the RFC specifications\footnote{\url{http://www.ietf.org/rfc.html}}. As of this project, we tend to put our focus on the protocols from Network Layer to Secure Layer in \Cref{Tbl: OSI} as a consideration of generality. Therefore, the following documents can be regarded as main references of protocol specifications:

\begin{itemize}
\item{RFC 791\cite{rfc791}} is the IPv4 specification. IPv4 is the most widely deployed protocol today. Even though its successor IPv6 has been proposed for more than a decade, the replacing process is taking place very slowly. It is expected that IPv4 will remain its dominance over the next few years.

\item{RFC 2460\cite{rfc2460}} is the IPv6 specification. IPv6 is the successor of IPv4. It was published in 1998 due to the exhaustion of IPv4 address. Although kernels today usually support both IPv4 and IPv6, many applications are still based on IPv4. However, as a “next generation” network, many IoT manufacturers also have the trend of adopting IPv6 as their standard.

\item{RFC 6282\cite{rfc6282}} is the specification for 6lowPAN. 6lowPAN is a compression header format for IPv6. It is designed for applications over constrained environments such as sensor networks where the resources, like bandwidth, are very limited. Comparing to a standard IPv6 header, a 6lowPAN header omits some fields by setting them to a default value suitable for constrained environments and hence  saved some bandwidth as well as processing time.

\item{RFC 6347\cite{rfc6347}} is the DTLS specification. DTLS is the counterpart of TLS over UDP. Since DTLS relies on UDP instead of TCP therefore it is considered to be more lightweight but unreliable. Even though UDP is designed to be connectionless in order to reduce its overhead, DTLS additionally (comparing to TLS) implemented some connection-oriented feature such as sequence to remain functional.

\item{RFC 7252\cite{rfc7252}} is the specification document for Constrained Application Protocol, CoAP. CoAP is a general application protocol for constrained environment. It has a similar design to HTTP which has a Request-Respond model and supports methods including GET, POST, PUT and DELETE. CoAP is designed to be able to map to HTTP for interoperability purpose.
\end{itemize}